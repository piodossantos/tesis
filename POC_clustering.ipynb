{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgMLLHeZVfIu"
      },
      "source": [
        "* Carga el video utilizando cv2.VideoCapture.\n",
        "* Extrae los frames del video uno por uno.\n",
        "* Preprocesa cada frame para que sean compatibles con el modelo de PyTorch (tamaño, normalización, etc.).\n",
        "* Usa un modelo preentrenado de PyTorch (como ResNet) para extraer características de cada frame.\n",
        "* Aplica un algoritmo de clustering (como K-Means) a las características extraídas.\n",
        "* Asigna cada frame al cluster correspondiente.\n",
        "* Visualiza los resultados mostrando los frames y su cluster correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G33AhGWGTLwl"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "from sklearn.cluster import AgglomerativeClustering,DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        " dev = \"cuda:0\"\n",
        "else:\n",
        " dev = \"cpu\"\n",
        "\n",
        "device = torch.device(dev)\n",
        "\n",
        "# Inicializa el modelo preentrenado de PyTorch\n",
        "model = models.resnet18(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "model = model.to(device)\n",
        "#summary(model,(3,224,224))\n",
        "model.eval()\n",
        "\n",
        "# Transformaciones para los frames del video\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(120),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "#TODO  imprimir preview de imagenes.\n",
        "\n",
        "\n",
        "# Leer video\n",
        "video_path = 'video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Extraer características de los frames del video\n",
        "features = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocesa el frame\n",
        "    input_tensor = preprocess(frame)\n",
        "    input_batch = input_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "    #print(\"input\",input_tensor.shape)\n",
        "    #plt.imshow(cv2.cvtColor(input_tensor.numpy().transpose(1,2,0), cv2.COLOR_BGR2RGB))\n",
        "    #plt.show()\n",
        "\n",
        "    # Extrae características\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "        #print(output.shape)\n",
        "\n",
        "    # Convierte las características a un formato compatible con sklearn\n",
        "    features.append(output.cpu().numpy().flatten())\n",
        "\n",
        "# Cierra el capturador de video\n",
        "cap.release()\n",
        "\n",
        "# Convierte la lista de características a un array de NumPy\n",
        "features = np.array(features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iVwFyfnbAsl9"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/mmandirola/tesis/POC_clustering.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m evaluator \u001b[39m=\u001b[39m DBSCAN(eps\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, min_samples\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#HDBScan\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m evaluator\u001b[39m.\u001b[39;49mfit(features)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cluster_labels \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39mlabels_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#print(evaluator.n_clusters_)\u001b[39;00m\n",
            "File \u001b[0;32m~/tesis/venv/lib/python3.10/site-packages/sklearn/cluster/_dbscan.py:368\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform DBSCAN clustering from features, or distance matrix.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \n\u001b[1;32m    344\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Returns a fitted instance of self.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 368\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    370\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
            "File \u001b[0;32m~/tesis/venv/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[0;32m~/tesis/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    907\u001b[0m         )\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ],
      "source": [
        "# Aplica K-Means clustering\n",
        "n_clusters = 5  # por ejemplo, 5 clusters\n",
        "\n",
        "evaluator = AgglomerativeClustering(n_clusters=None, distance_threshold=50)\n",
        "# evaluator = DBSCAN(eps=20, min_samples=5)\n",
        "#HDBScan\n",
        "evaluator.fit(features)\n",
        "cluster_labels = evaluator.labels_\n",
        "#print(evaluator.n_clusters_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KnXwyoBAvy4"
      },
      "outputs": [],
      "source": [
        "# Vuelve a leer el video para visualizar los resultados\n",
        "from collections import defaultdict\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_number = 0\n",
        "printed_labels = defaultdict(list)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Muestra el frame con la etiqueta del cluster\n",
        "    label = cluster_labels[frame_number]\n",
        "    printed_labels[label].append(frame)\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# Cierra el capturador de video\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1B8lDiVKpFr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_label_counts(labels_dict):\n",
        "    \"\"\"\n",
        "    Plots a bar chart showing the number of appearances of each label.\n",
        "\n",
        "    :param labels_dict: A dictionary where keys are labels and values are lists of frames.\n",
        "    \"\"\"\n",
        "    # Counting the number of frames for each label\n",
        "    label_counts = {label: len(frames) for label, frames in labels_dict.items()}\n",
        "    print(label_counts)\n",
        "    # Data for plotting\n",
        "    labels = list(label_counts.keys())\n",
        "    counts = list(label_counts.values())\n",
        "\n",
        "    # Creating the bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(labels, counts, color='pink')\n",
        "    plt.xlabel('Labels')\n",
        "    plt.ylabel('Number of Appearances')\n",
        "    plt.title('Number of Appearances of Labels in Frames')\n",
        "    plt.show()\n",
        "\n",
        "plot_label_counts(printed_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeInm1-zJNYY"
      },
      "outputs": [],
      "source": [
        "for label, frames in printed_labels.items():\n",
        "  frames_per_images = len(frames)\n",
        "  if(len(frames)>4):\n",
        "    frames_per_image = 4\n",
        "\n",
        "  plt.figure(figsize=(10, 5))\n",
        "\n",
        "  for idx, frame in enumerate(frames[:frames_per_image]):\n",
        "    #TODO Random\n",
        "    plt.subplot(1, frames_per_image, idx+1)  # 1 fila, 2 columnas, posición 2\n",
        "    plt.axis('off')\n",
        "    cv2.putText(frame, f'Cluster: {label}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OAnQS6pQOmoY"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'printed_labels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/mmandirola/tesis/POC_clustering.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sorted_labels \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(printed_labels\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mmandirola/tesis/POC_clustering.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sorted_labels):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'printed_labels' is not defined"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "sorted_labels = sorted(printed_labels.keys())\n",
        "\n",
        "plt.figure(figsize=(100, 100))\n",
        "\n",
        "for idx, label in enumerate(sorted_labels):\n",
        "\n",
        "  frames = printed_labels[label]\n",
        "  plt.subplot(1, len(sorted_labels), idx+ 1)\n",
        "  plt.axis('off')\n",
        "  # Calcula la imagen promedio\n",
        "  # Convierte las imágenes a float para evitar problemas de desbordamiento\n",
        "  average_frame = np.mean([frame.astype(np.float32) for frame in frames], axis=0)\n",
        "  average_frame = np.array(np.round(average_frame), dtype=np.uint8)\n",
        "\n",
        "  # Mostrar la imagen promedio\n",
        "  plt.imshow(cv2.cvtColor(average_frame, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7lGmxywOWR7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "from collections import namedtuple\n",
        "\n",
        "def tag_cluster(cluster_labels, tags,steps):\n",
        "  tagged_clusters = {}\n",
        "  for _ in range(steps):\n",
        "    shuffle_tags=np.random.permutation(tags)\n",
        "    for start, end, screen, action in shuffle_tags:\n",
        "      frames = cluster_labels[int(start):int(end)]\n",
        "      frames = list(filter( lambda x: x not in tagged_clusters.keys(), frames))\n",
        "      values, counter= np.unique(frames, return_counts=True)\n",
        "      if(len(counter)>0):\n",
        "        tagged_clusters[values[np.argmax(counter)]] = screen\n",
        "  result=[]\n",
        "  for frames in cluster_labels:\n",
        "    result.append(tagged_clusters.get(frames,\"NO_CLASS\"))\n",
        "  return result\n",
        "\n",
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    # Calcular la matriz de confusión\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Calcular precisión, recall, F1-score y exactitud\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return conf_matrix, precision, recall, f1, accuracy\n",
        "\n",
        "def show_metrics(experiment, ceonf_matrix, precision, recall, f1, accuracy):\n",
        "    print(\"Experiment name:\",experiment)\n",
        "    #print(f'Matriz de confusión:\\n{conf_matrix}')\n",
        "   # print(f'Precisión: {precision}')\n",
        "    #print(f'Recall: {recall}')\n",
        "    print(f'F1-score: {f1}')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "\n",
        "def eval_cluster(cluster_labels, tags,steps):\n",
        "  y_pred = tag_cluster(cluster_labels, tags,steps)\n",
        "  return eval(y_pred,tags,steps)\n",
        "\n",
        "def eval(y_pred, tags,steps):\n",
        "  y_true = []\n",
        "  for start, end, screen, action in tags:\n",
        "    y_true+=(end-start+1)*[screen]\n",
        "  return get_metrics(y_true,y_pred)\n",
        "\n",
        "\n",
        "def eval_massive_cluster(cluster_labels, tags,steps,epochs):\n",
        "  precision_list, recall_list, f1_list, accuracy_list =[],[],[],[]\n",
        "  for _ in range(epochs):\n",
        "    _, precision, recall, f1, accuracy = eval_cluster(cluster_labels, tags,steps)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    accuracy_list.append(accuracy)\n",
        "  return calculate_mean_var(precision_list,recall_list, f1_list, accuracy_list)\n",
        "\n",
        "def calculate_mean_var(precision_list, recall_list, f1_list, accuracy_list):\n",
        "    # Crear una namedtuple para los resultados\n",
        "    MetricsResults = namedtuple('MetricsResults', ['mean', 'std'])\n",
        "\n",
        "    # Calcular medias y varianzas para cada métrica usando numpy\n",
        "    precision_results = MetricsResults(np.mean(precision_list), np.std(precision_list))\n",
        "    recall_results = MetricsResults(np.mean(recall_list), np.std(recall_list))\n",
        "    f1_results = MetricsResults(np.mean(f1_list), np.std(f1_list))\n",
        "    accuracy_results = MetricsResults(np.mean(accuracy_list), np.std(accuracy_list))\n",
        "\n",
        "    # Crear una namedtuple para agrupar los resultados\n",
        "    OverallResults = namedtuple('OverallResults', ['precision', 'recall', 'f1', 'accuracy'])\n",
        "\n",
        "    return OverallResults(precision=precision_results, recall=recall_results, f1=f1_results, accuracy=accuracy_results)\n",
        "\n",
        "def show_metrics_massive(experiment,epochs, overall_results):\n",
        "    print(\"Experiment name:\",experiment)\n",
        "    print(\"Epochs: \",epochs)\n",
        "    print(\"Precision - Mean: {:.2f}, std: {:.10f}\".format(overall_results.precision.mean, overall_results.precision.std))\n",
        "    print(\"Recall - Mean: {:.2f}, std: {:.10f}\".format(overall_results.recall.mean, overall_results.recall.std))\n",
        "    print(\"F1-Score - Mean: {:.2f}, std: {:.10f}\".format(overall_results.f1.mean, overall_results.f1.std))\n",
        "    print(\"Accuracy - Mean: {:.2f}, std: {:.10f}\".format(overall_results.accuracy.mean, overall_results.accuracy.std))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjaXMMqYZPBU"
      },
      "outputs": [],
      "source": [
        "\n",
        "frames_actions_original = [\n",
        "   (1, 119, 'Splash screen', 'Idle'),\n",
        "  (120, 186, 'Home screen', 'Idle'),\n",
        "  (187, 350, 'Buy action', 'Touch screen'),\n",
        "  (351, 357, 'Buy screen', 'Idle'),\n",
        "  (358, 502, 'Buy screen', 'Scrolling'),\n",
        "  (503, 545, 'Buy screen', 'Idle'),\n",
        "  (546, 647, 'Product detail screen', 'Touch screen'),\n",
        "  (648, 692, 'Cart screen', 'Idle'),\n",
        "  (693, 768, 'Add to cart', 'Touch screen'),\n",
        "  (769, 791, 'Buy screen', 'Idle'),\n",
        "  (792, 888, 'View cart', 'Touch screen'),\n",
        "  (889, 901, 'Cart screen', 'Idle'),\n",
        "  (902, 1001, 'Pay', 'Touch screen'),\n",
        "  (1002, 1137, 'Cart details', 'Idle'),\n",
        "]\n",
        "\n",
        "frames_actions_custom = [\n",
        "    (1, 120, 'carga la app',''),\n",
        "    (121, 200, 'home',''),\n",
        "    (201, 294, 'clic en comprar loading',''),\n",
        "    (295, 545, 'lista de productos',''),\n",
        "    (546, 603, 'hace clic en una hamburguesa y loading',''),\n",
        "    (604, 692, 'detalle de producto',''),\n",
        "    (693, 767, 'agregar producto al carro loading',''),\n",
        "    (768, 792, 'lista de productos',''),\n",
        "    (793, 854, 'voy al carrito y loading',''),\n",
        "    (855, 901, 'carrito',''),\n",
        "    (902, 1009, 'pagar y loading',''),\n",
        "    (1010, 1137, 'detail of pay',''),\n",
        "]\n",
        "\n",
        "epochs = 10\n",
        "steps=1\n",
        "\n",
        "show_metrics_massive(\"Dataset cliente\",epochs,eval_massive_cluster(cluster_labels, frames_actions_original,steps,epochs))\n",
        "print()\n",
        "show_metrics_massive(\"Dataset tagueado\",epochs,eval_massive_cluster(cluster_labels, frames_actions_custom,steps,epochs))\n",
        "\n",
        "\n",
        "# print(eval(cluster_labels, frames_actions_original))\n",
        "# print(eval(cluster_labels, frames_actions_custom))\n",
        "\n",
        "# Ahora frames_actions es una lista de tuplas, donde cada tupla representa un rango de frames y sus correspondientes acciones.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
